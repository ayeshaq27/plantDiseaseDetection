{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932cf017",
   "metadata": {},
   "source": [
    "# 04 — Transfer Learning with ResNet18\n",
    "\n",
    "This notebook uses transfer learning to train a high-performance plant disease classifier.\n",
    "Instead of training a CNN from scratch, we load a pretrained ResNet18 model trained on ImageNet.\n",
    "We replace the final layer and fine-tune the model on our PlantVillage dataset.\n",
    "This method dramatically improves accuracy and reduces training time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bc2cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basic PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#pretrained models + image transforms\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from dataset import PlantVillageDataset\n",
    "from train_utils import train_one_epoch, validate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a907040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms prepare images the way ResNet18 expects\n",
    "#ImageNet-trained models need imgs resized to 224x224 and normalized to specific vals\n",
    "#ImageNet -> dataset\n",
    "#ResNet -> model, type of nn\n",
    "train_transforms = transforms.Compose([\n",
    "  transforms.Resize((160,160)), #size needed for ResNet\n",
    "  #augmentation: change orientation of imgs while training so it can recognize disease regardless if leaf is flipped or rotated\n",
    "  transforms.RandomHorizontalFlip(), # flips left or right randomly\n",
    "  transforms.RandomRotation(10), # rotates images randomly between -10 deg and 20 deg\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(#standard imagenet normalization using z-score standardization\n",
    "    mean=[0.485,0.456,0.406], \n",
    "    std=[0.229,0.224,0.225]\n",
    "  )\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "  #no augmentation for val bc validation must reflect real unmodified images\n",
    "  transforms.Resize((160,160)),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(\n",
    "    mean=[0.485,0.456,0.406],\n",
    "    std=[0.229,0.224,0.225]\n",
    "  )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdeede98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset then apply transforms\n",
    "train_dataset = PlantVillageDataset(\"../data/PlantVillage/train\", transform=train_transforms)\n",
    "val_dataset = PlantVillageDataset(\"../data/PlantVillage/val\", transform=val_transforms)\n",
    "\n",
    "#loaders to feed data in small batches while training\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4828b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained ResNet18\n",
    "#model has already learned features from 1.2 mil images (through ImageNet)\n",
    "# -------------------------------\n",
    "# LOAD RESNET18 PRETRAINED MODEL\n",
    "# -------------------------------\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Number of plant disease classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# Replace the final classification layer so it matches plant disease labels\n",
    "model.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "# Move model to CPU or GPU depending on your system\n",
    "model = model.to(device)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# FREEZE THE EARLY LAYERS (so they don't get updated)\n",
    "# --------------------------------------------------\n",
    "# ResNet18 has multiple \"children\" (layers).\n",
    "# We freeze the first ~6 layers because they learn VERY basic features\n",
    "# like edges, curves, textures — these features work for almost any image.\n",
    "layer_counter = 0\n",
    "for child in model.children():\n",
    "    layer_counter += 1\n",
    "    \n",
    "    # Freeze layers 1–6\n",
    "    if layer_counter < 7:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "# Only the later layers + final layer will train.\n",
    "# This reduces training time A LOT while keeping high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9c61b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE OPTIMIZER (only trains unfrozen layers)\n",
    "# --------------------------------------------\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-4 #learning rate\n",
    ")\n",
    "\n",
    "# Standard classification loss\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8fa521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Running: Training Epoch\n",
      "Running: Validation epoch\n",
      "Train Loss: 0.2412, Train Acc: 0.9357\n",
      "Val Loss: 0.0533, Val Acc: 0.9843\n",
      "--------------------------------------------------\n",
      "Epoch 2/5\n",
      "Running: Training Epoch\n",
      "Running: Validation epoch\n",
      "Train Loss: 0.0712, Train Acc: 0.9784\n",
      "Val Loss: 0.0428, Val Acc: 0.9852\n",
      "--------------------------------------------------\n",
      "Epoch 3/5\n",
      "Running: Training Epoch\n",
      "Running: Validation epoch\n",
      "Train Loss: 0.0525, Train Acc: 0.9834\n",
      "Val Loss: 0.0316, Val Acc: 0.9893\n",
      "--------------------------------------------------\n",
      "Epoch 4/5\n",
      "Running: Training Epoch\n",
      "Running: Validation epoch\n",
      "Train Loss: 0.0430, Train Acc: 0.9866\n",
      "Val Loss: 0.0295, Val Acc: 0.9906\n",
      "--------------------------------------------------\n",
      "Epoch 5/5\n",
      "Running: Training Epoch\n",
      "Running: Validation epoch\n",
      "Train Loss: 0.0347, Train Acc: 0.9888\n",
      "Val Loss: 0.0266, Val Acc: 0.9917\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "  print(\"Running: Training Epoch\")\n",
    "  train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "  \n",
    "  print(\"Running: Validation epoch\")\n",
    "  val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "\n",
    "  print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "  print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "  print(\"-\" * 50)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "387ffce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models/resnet18_best.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (plant-env)",
   "language": "python",
   "name": "plant-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
