{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2ccabc",
   "metadata": {},
   "source": [
    "05 — Model Evaluation & Inference\n",
    "\n",
    "This notebook evaluates the ResNet18 model trained in Notebook 04. The goal is to measure how well the model performs on unseen images and understand where it succeeds or struggles.\n",
    "\n",
    "What’s included:\n",
    "1. Load the trained model: \n",
    "    Rebuild the ResNet18 architecture and load the saved .pth weights.\n",
    "2. Prepare the test dataset: \n",
    "    Apply the same transforms used during validation and load images for evaluation.\n",
    "3. Compute test accuracy: \n",
    "    Measure the model’s performance on unseen data.\n",
    "4. Confusion matrix: \n",
    "    Visualize which classes the model predicts correctly and which ones it mixes up.\n",
    "5. Sample predictions: \n",
    "    Display test images with true and predicted labels.\n",
    "6. Misclassified samples: \n",
    "    Inspect the images the model got wrong to understand common mistakes.\n",
    "7. Custom image inference: \n",
    "    Test the model on your own image to see how it performs outside the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataset import PlantVillageDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39191e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "  transforms.Resize((160,160)),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229,0.224,0.225]\n",
    "  )\n",
    "])\n",
    "\n",
    "test_dataset = PlantVillageDataset(\n",
    "  \"../data/PlantVillage/val\",\n",
    "  transform=test_transforms\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Classes: {test_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b07be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=None) #no pretrained weights\n",
    "num_classes = len(test_dataset.classes)\n",
    "model.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "#load trained weights\n",
    "model.load_state_dict(torch.load(\"../models/resnet18_best.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval() #evalualion mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute accuracy\n",
    "correct = 0 \n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    outputs = model(images)\n",
    "    _,preds = torch.max(outputs, 1)\n",
    "\n",
    "    correct += (preds == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "test_acc = correct / total\n",
    "print(f\"Final Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45446bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix -> table that shows how model actually performed for each class\n",
    "#each row reps what leaf actually is\n",
    "#each col reps what the model guessed\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "#not training, so no gradients are computed\n",
    "with torch.no_grad():\n",
    "  for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    outputs = model(images) #get model preds\n",
    "\n",
    "    #torch_max(...,1) returns:\n",
    "    # preds = idx of highest score -> pred class\n",
    "    _, preds = torch.ax(outputs, 1)\n",
    "\n",
    "    #save preds and true labels into py lists\n",
    "    #just incase it does use gpu, we need to move to cpu since numoy needs it\n",
    "    all_preds.extend(preds.cpu().numpy())\n",
    "    all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "#build confusion mtx\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "#normalize so each row values are in range 0-1\n",
    "#shows % of preds per class\n",
    "cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm_norm, annot=False, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (Normalized)\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf24c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_preds(model, dataset, num_imgs=6):\n",
    "  model.eval()\n",
    "  plt.figure(figsize=(14,8))\n",
    "\n",
    "  for i in range(num_imgs):\n",
    "    img,label = dataset[i]\n",
    "    img_display = img.permute(1,2,0) # convert from tensor CHW to HWC\n",
    "    img_batch = img.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      output = model(img_batch)\n",
    "      _,pred  = torch.max(output, 1)\n",
    "\n",
    "      true_class = dataset.classes[label]\n",
    "      pred_class = dataset.classes[pred.item()]\n",
    "\n",
    "      plt.subplot(2,3,i+1)\n",
    "      plt.imshow(img_display)\n",
    "      plt.title(f\"True: {true_class}\\nPred: {pred_class}\")\n",
    "      plt.axis(\"off\")\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "show_preds(model, test_dataset, num_imgs=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (plant-env)",
   "language": "python",
   "name": "plant-env"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
